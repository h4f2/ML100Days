{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVq5E9P9RNOm"
   },
   "source": [
    "作業目標:<br>\r\n",
    "1. 熟悉索引操作\r\n",
    "2. 分辨合併資料方法使用時機"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dJGNbEQR9fw"
   },
   "source": [
    "作業重點:<br>\r\n",
    "1. 操作索引注意有分loc、iloc\r\n",
    "2. 合併資料方法concat、merge、join其中有參數可以調整inner或outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm-gS3tlRQFU"
   },
   "source": [
    "題目:<br>\r\n",
    "讀取STOCK_DAY_0050_202009.csv串聯STOCK_DAY_0050_202010.csv，並且找出open小於close的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "c28Som-RRO7s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ie41WfAQwcCS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    open    high     low   close\n",
      "0   109/09/01  102.45  103.35  101.85  103.35\n",
      "1   109/09/02  103.65  104.05  102.30  103.00\n",
      "2   109/09/03  103.70  104.30  103.20  103.30\n",
      "3   109/09/04  102.00  102.70  101.90  102.55\n",
      "4   109/09/07  102.55  103.05  101.90  102.40\n",
      "5   109/09/08  102.75  103.10  102.45  103.00\n",
      "6   109/09/09  101.75  102.35  101.15  102.30\n",
      "7   109/09/10  102.80  103.35  102.60  103.20\n",
      "8   109/09/11  103.20  103.35  102.80  103.25\n",
      "9   109/09/14  103.50  104.55  103.25  104.55\n",
      "10  109/09/15  104.45  105.20  104.25  104.95\n",
      "11  109/09/16  106.55  107.00  106.35  106.55\n",
      "12  109/09/17  106.05  106.35  105.10  105.40\n",
      "13  109/09/18  105.40  105.70  104.85  105.30\n",
      "14  109/09/21  105.20  105.90  104.35  104.45\n",
      "15  109/09/22  104.30  104.30  102.95  103.10\n",
      "16  109/09/23  103.50  103.50  102.40  102.95\n",
      "17  109/09/24  101.55  101.80  100.25  100.45\n",
      "18  109/09/25  100.75  101.45  100.05  100.65\n",
      "19  109/09/28  101.35  102.30  101.00  102.30\n",
      "20  109/09/29  102.75  103.50  102.15  102.55\n",
      "21  109/09/30  102.75  103.45  102.60  103.00\n",
      "         date    open    high     low   close\n",
      "0   109/10/05  103.45  104.05  103.00  103.05\n",
      "1   109/10/06  104.00  104.35  103.85  104.25\n",
      "2   109/10/07  104.00  105.00  103.50  104.80\n",
      "3   109/10/08  105.45  106.35  105.30  106.20\n",
      "4   109/10/12  106.70  107.70  106.70  107.05\n",
      "5   109/10/13  107.35  107.60  106.20  107.10\n",
      "6   109/10/14  107.05  107.20  106.45  106.70\n",
      "7   109/10/15  106.50  106.50  105.10  105.70\n",
      "8   109/10/16  105.70  106.30  105.10  105.25\n",
      "9   109/10/19  105.65  106.60  105.60  106.60\n",
      "10  109/10/20  106.40  106.45  106.00  106.00\n",
      "11  109/10/21  106.00  106.55  105.65  105.95\n",
      "12  109/10/22  105.70  106.10  105.50  106.10\n",
      "13  109/10/23  106.50  106.65  105.65  106.10\n",
      "14  109/10/26  106.10  106.60  105.80  106.10\n",
      "15  109/10/27  105.75  105.75  105.15  105.50\n",
      "16  109/10/28  105.50  105.50  104.80  105.00\n",
      "17  109/10/29  104.00  104.10  103.25  103.85\n",
      "18  109/10/30  103.55  103.60  102.70  103.00\n"
     ]
    }
   ],
   "source": [
    "#讀取STOCK_DAY_0050_202009.csv、STOCK_DAY_0050_202010.csv\n",
    "df_202009=pd.read_csv('./Pandas_select_merge/STOCK_DAY_0050_202009.csv')\n",
    "df_202010=pd.read_csv('./Pandas_select_merge/STOCK_DAY_0050_202010.csv')\n",
    "print(df_202009)\n",
    "print(df_202010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "HwABxdTXwcCT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    open    high     low   close\n",
      "0   109/09/01  102.45  103.35  101.85  103.35\n",
      "1   109/09/02  103.65  104.05  102.30  103.00\n",
      "2   109/09/03  103.70  104.30  103.20  103.30\n",
      "3   109/09/04  102.00  102.70  101.90  102.55\n",
      "4   109/09/07  102.55  103.05  101.90  102.40\n",
      "5   109/09/08  102.75  103.10  102.45  103.00\n",
      "6   109/09/09  101.75  102.35  101.15  102.30\n",
      "7   109/09/10  102.80  103.35  102.60  103.20\n",
      "8   109/09/11  103.20  103.35  102.80  103.25\n",
      "9   109/09/14  103.50  104.55  103.25  104.55\n",
      "10  109/09/15  104.45  105.20  104.25  104.95\n",
      "11  109/09/16  106.55  107.00  106.35  106.55\n",
      "12  109/09/17  106.05  106.35  105.10  105.40\n",
      "13  109/09/18  105.40  105.70  104.85  105.30\n",
      "14  109/09/21  105.20  105.90  104.35  104.45\n",
      "15  109/09/22  104.30  104.30  102.95  103.10\n",
      "16  109/09/23  103.50  103.50  102.40  102.95\n",
      "17  109/09/24  101.55  101.80  100.25  100.45\n",
      "18  109/09/25  100.75  101.45  100.05  100.65\n",
      "19  109/09/28  101.35  102.30  101.00  102.30\n",
      "20  109/09/29  102.75  103.50  102.15  102.55\n",
      "21  109/09/30  102.75  103.45  102.60  103.00\n",
      "22  109/10/05  103.45  104.05  103.00  103.05\n",
      "23  109/10/06  104.00  104.35  103.85  104.25\n",
      "24  109/10/07  104.00  105.00  103.50  104.80\n",
      "25  109/10/08  105.45  106.35  105.30  106.20\n",
      "26  109/10/12  106.70  107.70  106.70  107.05\n",
      "27  109/10/13  107.35  107.60  106.20  107.10\n",
      "28  109/10/14  107.05  107.20  106.45  106.70\n",
      "29  109/10/15  106.50  106.50  105.10  105.70\n",
      "30  109/10/16  105.70  106.30  105.10  105.25\n",
      "31  109/10/19  105.65  106.60  105.60  106.60\n",
      "32  109/10/20  106.40  106.45  106.00  106.00\n",
      "33  109/10/21  106.00  106.55  105.65  105.95\n",
      "34  109/10/22  105.70  106.10  105.50  106.10\n",
      "35  109/10/23  106.50  106.65  105.65  106.10\n",
      "36  109/10/26  106.10  106.60  105.80  106.10\n",
      "37  109/10/27  105.75  105.75  105.15  105.50\n",
      "38  109/10/28  105.50  105.50  104.80  105.00\n",
      "39  109/10/29  104.00  104.10  103.25  103.85\n",
      "40  109/10/30  103.55  103.60  102.70  103.00\n"
     ]
    }
   ],
   "source": [
    "#串聯\n",
    "df=pd.DataFrame.merge(df_202009,df_202010,how='outer')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_omQWydWwcCT",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    open    high     low   close\n",
      "0   109/09/01  102.45  103.35  101.85  103.35\n",
      "3   109/09/04  102.00  102.70  101.90  102.55\n",
      "5   109/09/08  102.75  103.10  102.45  103.00\n",
      "6   109/09/09  101.75  102.35  101.15  102.30\n",
      "7   109/09/10  102.80  103.35  102.60  103.20\n",
      "8   109/09/11  103.20  103.35  102.80  103.25\n",
      "9   109/09/14  103.50  104.55  103.25  104.55\n",
      "10  109/09/15  104.45  105.20  104.25  104.95\n",
      "19  109/09/28  101.35  102.30  101.00  102.30\n",
      "21  109/09/30  102.75  103.45  102.60  103.00\n",
      "23  109/10/06  104.00  104.35  103.85  104.25\n",
      "24  109/10/07  104.00  105.00  103.50  104.80\n",
      "25  109/10/08  105.45  106.35  105.30  106.20\n",
      "26  109/10/12  106.70  107.70  106.70  107.05\n",
      "31  109/10/19  105.65  106.60  105.60  106.60\n",
      "34  109/10/22  105.70  106.10  105.50  106.10\n"
     ]
    }
   ],
   "source": [
    "#找出open小於close的資料\n",
    "print(df[df['open'] < df['close']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mFib7gxHwcCU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function merge in module pandas.core.frame:\n",
      "\n",
      "merge(self, right, how='inner', on=None, left_on=None, right_on=None, left_index=False, right_index=False, sort=False, suffixes=('_x', '_y'), copy=True, indicator=False, validate=None) -> 'DataFrame'\n",
      "    Merge DataFrame or named Series objects with a database-style join.\n",
      "    \n",
      "    The join is done on columns or indexes. If joining columns on\n",
      "    columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes\n",
      "    on indexes or indexes on a column or columns, the index will be passed on.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    right : DataFrame or named Series\n",
      "        Object to merge with.\n",
      "    how : {'left', 'right', 'outer', 'inner'}, default 'inner'\n",
      "        Type of merge to be performed.\n",
      "    \n",
      "        * left: use only keys from left frame, similar to a SQL left outer join;\n",
      "          preserve key order.\n",
      "        * right: use only keys from right frame, similar to a SQL right outer join;\n",
      "          preserve key order.\n",
      "        * outer: use union of keys from both frames, similar to a SQL full outer\n",
      "          join; sort keys lexicographically.\n",
      "        * inner: use intersection of keys from both frames, similar to a SQL inner\n",
      "          join; preserve the order of the left keys.\n",
      "    on : label or list\n",
      "        Column or index level names to join on. These must be found in both\n",
      "        DataFrames. If `on` is None and not merging on indexes then this defaults\n",
      "        to the intersection of the columns in both DataFrames.\n",
      "    left_on : label or list, or array-like\n",
      "        Column or index level names to join on in the left DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the left DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    right_on : label or list, or array-like\n",
      "        Column or index level names to join on in the right DataFrame. Can also\n",
      "        be an array or list of arrays of the length of the right DataFrame.\n",
      "        These arrays are treated as if they are columns.\n",
      "    left_index : bool, default False\n",
      "        Use the index from the left DataFrame as the join key(s). If it is a\n",
      "        MultiIndex, the number of keys in the other DataFrame (either the index\n",
      "        or a number of columns) must match the number of levels.\n",
      "    right_index : bool, default False\n",
      "        Use the index from the right DataFrame as the join key. Same caveats as\n",
      "        left_index.\n",
      "    sort : bool, default False\n",
      "        Sort the join keys lexicographically in the result DataFrame. If False,\n",
      "        the order of the join keys depends on the join type (how keyword).\n",
      "    suffixes : tuple of (str, str), default ('_x', '_y')\n",
      "        Suffix to apply to overlapping column names in the left and right\n",
      "        side, respectively. To raise an exception on overlapping columns use\n",
      "        (False, False).\n",
      "    copy : bool, default True\n",
      "        If False, avoid copy if possible.\n",
      "    indicator : bool or str, default False\n",
      "        If True, adds a column to output DataFrame called \"_merge\" with\n",
      "        information on the source of each row.\n",
      "        If string, column with information on source of each row will be added to\n",
      "        output DataFrame, and column will be named value of string.\n",
      "        Information column is Categorical-type and takes on a value of \"left_only\"\n",
      "        for observations whose merge key only appears in 'left' DataFrame,\n",
      "        \"right_only\" for observations whose merge key only appears in 'right'\n",
      "        DataFrame, and \"both\" if the observation's merge key is found in both.\n",
      "    \n",
      "    validate : str, optional\n",
      "        If specified, checks if merge is of specified type.\n",
      "    \n",
      "        * \"one_to_one\" or \"1:1\": check if merge keys are unique in both\n",
      "          left and right datasets.\n",
      "        * \"one_to_many\" or \"1:m\": check if merge keys are unique in left\n",
      "          dataset.\n",
      "        * \"many_to_one\" or \"m:1\": check if merge keys are unique in right\n",
      "          dataset.\n",
      "        * \"many_to_many\" or \"m:m\": allowed, but does not result in checks.\n",
      "    \n",
      "        .. versionadded:: 0.21.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    DataFrame\n",
      "        A DataFrame of the two merged objects.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    merge_ordered : Merge with optional filling/interpolation.\n",
      "    merge_asof : Merge on nearest keys.\n",
      "    DataFrame.join : Similar method using indices.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Support for specifying index levels as the `on`, `left_on`, and\n",
      "    `right_on` parameters was added in version 0.23.0\n",
      "    Support for merging named Series objects was added in version 0.24.0\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'lkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [1, 2, 3, 5]})\n",
      "    >>> df2 = pd.DataFrame({'rkey': ['foo', 'bar', 'baz', 'foo'],\n",
      "    ...                     'value': [5, 6, 7, 8]})\n",
      "    >>> df1\n",
      "        lkey value\n",
      "    0   foo      1\n",
      "    1   bar      2\n",
      "    2   baz      3\n",
      "    3   foo      5\n",
      "    >>> df2\n",
      "        rkey value\n",
      "    0   foo      5\n",
      "    1   bar      6\n",
      "    2   baz      7\n",
      "    3   foo      8\n",
      "    \n",
      "    Merge df1 and df2 on the lkey and rkey columns. The value columns have\n",
      "    the default suffixes, _x and _y, appended.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey')\n",
      "      lkey  value_x rkey  value_y\n",
      "    0  foo        1  foo        5\n",
      "    1  foo        1  foo        8\n",
      "    2  foo        5  foo        5\n",
      "    3  foo        5  foo        8\n",
      "    4  bar        2  bar        6\n",
      "    5  baz        3  baz        7\n",
      "    \n",
      "    Merge DataFrames df1 and df2 with specified left and right suffixes\n",
      "    appended to any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey',\n",
      "    ...           suffixes=('_left', '_right'))\n",
      "      lkey  value_left rkey  value_right\n",
      "    0  foo           1  foo            5\n",
      "    1  foo           1  foo            8\n",
      "    2  foo           5  foo            5\n",
      "    3  foo           5  foo            8\n",
      "    4  bar           2  bar            6\n",
      "    5  baz           3  baz            7\n",
      "    \n",
      "    Merge DataFrames df1 and df2, but raise an exception if the DataFrames have\n",
      "    any overlapping columns.\n",
      "    \n",
      "    >>> df1.merge(df2, left_on='lkey', right_on='rkey', suffixes=(False, False))\n",
      "    Traceback (most recent call last):\n",
      "    ...\n",
      "    ValueError: columns overlap but no suffix specified:\n",
      "        Index(['value'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.merge)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas_select_merge_hw題目.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
